services:
  db:
    image: postgres:16
    environment:
      POSTGRES_DB: rag
      POSTGRES_USER: rag
      POSTGRES_PASSWORD: rag
    ports:
      - "${PG_PORT:-56473}:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rag -d rag"]
      interval: 5s
      timeout: 5s
      retries: 20

  qdrant:
    image: qdrant/qdrant:v1.11.3
    ports:
      - "${QDRANT_PORT:-6333}:6333"
    volumes:
      - ../var/qdrant:/qdrant/storage

  api:
    build:
      context: ..
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://rag:rag@db:5432/rag
      QDRANT_URL: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
      QDRANT_COLLECTION: ${QDRANT_COLLECTION:-rag_segments}
      # Provider-neutral (preferred). Leave unset to use LMSTUDIO_* defaults below.
      INFERENCE_BASE_URL: ${INFERENCE_BASE_URL:-}
      INFERENCE_API_KEY: ${INFERENCE_API_KEY:-}
      INFERENCE_CHAT_MODEL: ${INFERENCE_CHAT_MODEL:-}
      INFERENCE_EMBEDDING_MODEL: ${INFERENCE_EMBEDDING_MODEL:-}
      # Optional split providers (override INFERENCE_* for their respective purpose).
      CHAT_BASE_URL: ${CHAT_BASE_URL:-}
      CHAT_API_KEY: ${CHAT_API_KEY:-}
      CHAT_MODEL: ${CHAT_MODEL:-}
      CHAT_BACKEND: ${CHAT_BACKEND:-}
      CHAT_VERTEX_PROJECT: ${CHAT_VERTEX_PROJECT:-}
      CHAT_VERTEX_LOCATION: ${CHAT_VERTEX_LOCATION:-}
      CHAT_VERTEX_CREDENTIALS: ${CHAT_VERTEX_CREDENTIALS:-}
      EMBEDDINGS_BASE_URL: ${EMBEDDINGS_BASE_URL:-}
      EMBEDDINGS_API_KEY: ${EMBEDDINGS_API_KEY:-}
      EMBEDDINGS_MODEL: ${EMBEDDINGS_MODEL:-}
      EMBEDDINGS_BACKEND: ${EMBEDDINGS_BACKEND:-openai_compat}
      EMBEDDINGS_VERTEX_PROJECT: ${EMBEDDINGS_VERTEX_PROJECT:-}
      EMBEDDINGS_VERTEX_LOCATION: ${EMBEDDINGS_VERTEX_LOCATION:-}
      EMBEDDINGS_VERTEX_CREDENTIALS: ${EMBEDDINGS_VERTEX_CREDENTIALS:-}
      EMBEDDING_DIM: ${EMBEDDING_DIM:-}
      # From Docker Desktop on macOS:
      LMSTUDIO_BASE_URL: ${LMSTUDIO_BASE_URL:-http://host.docker.internal:1234/v1}
      LMSTUDIO_API_KEY: ${LMSTUDIO_API_KEY:-}
      LMSTUDIO_CHAT_MODEL: ${LMSTUDIO_CHAT_MODEL:-local-model}
      LMSTUDIO_EMBEDDING_MODEL: ${LMSTUDIO_EMBEDDING_MODEL:-local-embedding-model}
      TOP_K: ${TOP_K:-6}
      MAX_CONTEXT_CHARS: ${MAX_CONTEXT_CHARS:-24000}
      RETRIEVAL_USE_FTS: ${RETRIEVAL_USE_FTS:-1}
      RERANKING_STRATEGY: ${RERANKING_STRATEGY:-none}
      RERANKING_RETRIEVAL_K: ${RERANKING_RETRIEVAL_K:-40}
      RERANKING_BASE_URL: ${RERANKING_BASE_URL:-}
      RERANKING_API_KEY: ${RERANKING_API_KEY:-}
      RERANKING_MODEL: ${RERANKING_MODEL:-}
      RERANKING_BATCH_SIZE: ${RERANKING_BATCH_SIZE:-16}
      ALLOW_ANONYMOUS: ${ALLOW_ANONYMOUS:-false}
      LOG_PROMPTS: ${LOG_PROMPTS:-}
      LOG_COMPLETIONS: ${LOG_COMPLETIONS:-}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-pretty}
    ports:
      - "${API_PORT:-18080}:8080"
    volumes:
      - ../var/gcp:/app/var/gcp:ro
    depends_on:
      db:
        condition: service_healthy
      qdrant:
        condition: service_started
