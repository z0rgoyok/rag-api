services:
  db:
    image: postgres:16
    environment:
      POSTGRES_DB: rag
      POSTGRES_USER: rag
      POSTGRES_PASSWORD: rag
    ports:
      - "${PG_PORT:-56473}:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rag -d rag"]
      interval: 5s
      timeout: 5s
      retries: 20

  qdrant:
    image: qdrant/qdrant:v1.11.3
    ports:
      - "${QDRANT_PORT:-6333}:6333"
    volumes:
      - ../var/qdrant:/qdrant/storage

  api:
    build:
      context: ..
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://rag:rag@db:5432/rag
      QDRANT_URL: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
      QDRANT_COLLECTION: ${QDRANT_COLLECTION:-rag_segments}
      # Provider-neutral (preferred). Leave unset to use LMSTUDIO_* defaults below.
      INFERENCE_BASE_URL: ${INFERENCE_BASE_URL:-}
      INFERENCE_API_KEY: ${INFERENCE_API_KEY:-}
      INFERENCE_CHAT_MODEL: ${INFERENCE_CHAT_MODEL:-}
      INFERENCE_EMBEDDING_MODEL: ${INFERENCE_EMBEDDING_MODEL:-}
      # Optional split providers (override INFERENCE_* for their respective purpose).
      CHAT_BASE_URL: ${CHAT_BASE_URL:-}
      CHAT_API_KEY: ${CHAT_API_KEY:-}
      CHAT_MODEL: ${CHAT_MODEL:-}
      CHAT_BACKEND: ${CHAT_BACKEND:-}
      CHAT_VERTEX_PROJECT: ${CHAT_VERTEX_PROJECT:-}
      CHAT_VERTEX_LOCATION: ${CHAT_VERTEX_LOCATION:-}
      CHAT_VERTEX_CREDENTIALS: ${CHAT_VERTEX_CREDENTIALS:-}
      EMBEDDINGS_BASE_URL: ${EMBEDDINGS_BASE_URL:-}
      EMBEDDINGS_API_KEY: ${EMBEDDINGS_API_KEY:-}
      EMBEDDINGS_MODEL: ${EMBEDDINGS_MODEL:-}
      EMBEDDINGS_BACKEND: ${EMBEDDINGS_BACKEND:-openai_compat}
      EMBEDDINGS_VERTEX_PROJECT: ${EMBEDDINGS_VERTEX_PROJECT:-}
      EMBEDDINGS_VERTEX_LOCATION: ${EMBEDDINGS_VERTEX_LOCATION:-}
      EMBEDDINGS_VERTEX_CREDENTIALS: ${EMBEDDINGS_VERTEX_CREDENTIALS:-}
      EMBEDDING_DIM: ${EMBEDDING_DIM:-}
      # From Docker Desktop on macOS:
      LMSTUDIO_BASE_URL: ${LMSTUDIO_BASE_URL:-http://host.docker.internal:1234/v1}
      LMSTUDIO_API_KEY: ${LMSTUDIO_API_KEY:-}
      LMSTUDIO_CHAT_MODEL: ${LMSTUDIO_CHAT_MODEL:-local-model}
      LMSTUDIO_EMBEDDING_MODEL: ${LMSTUDIO_EMBEDDING_MODEL:-local-embedding-model}
      TOP_K: ${TOP_K:-6}
      MAX_CONTEXT_CHARS: ${MAX_CONTEXT_CHARS:-24000}
      RETRIEVAL_USE_FTS: ${RETRIEVAL_USE_FTS:-1}
      RERANKING_STRATEGY: ${RERANKING_STRATEGY:-none}
      RERANKING_RETRIEVAL_K: ${RERANKING_RETRIEVAL_K:-40}
      RERANKING_BASE_URL: ${RERANKING_BASE_URL:-}
      RERANKING_API_KEY: ${RERANKING_API_KEY:-}
      RERANKING_MODEL: ${RERANKING_MODEL:-}
      RERANKING_BATCH_SIZE: ${RERANKING_BATCH_SIZE:-16}
      ALLOW_ANONYMOUS: ${ALLOW_ANONYMOUS:-false}
      LOG_PROMPTS: ${LOG_PROMPTS:-}
      LOG_COMPLETIONS: ${LOG_COMPLETIONS:-}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-pretty}
    ports:
      - "${API_PORT:-18080}:8080"
    volumes:
      - ../var/gcp:/app/var/gcp:ro
    depends_on:
      db:
        condition: service_healthy
      qdrant:
        condition: service_started

  nextchat:
    image: yidadaa/chatgpt-next-web:latest
    environment:
      # NextChat appends /v1 internally; keep BASE_URL without /v1 suffix.
      BASE_URL: ${NEXTCHAT_BASE_URL:-http://api:8080}
      OPENAI_API_KEY: ${NEXTCHAT_OPENAI_API_KEY:-}
      CUSTOM_MODELS: ${NEXTCHAT_CUSTOM_MODELS:-}
      DEFAULT_MODEL: ${NEXTCHAT_DEFAULT_MODEL:-}
      CODE: ${NEXTCHAT_CODE:-}
      NEXTCHAT_ENABLE_REALTIME_DEFAULT: ${NEXTCHAT_ENABLE_REALTIME_DEFAULT:-1}
    command:
      - /bin/sh
      - -lc
      - |
        set -e
        if [ "$${NEXTCHAT_ENABLE_REALTIME_DEFAULT:-1}" = "1" ] || [ "$${NEXTCHAT_ENABLE_REALTIME_DEFAULT:-}" = "true" ]; then
          pattern='realtimeConfig:{enable:!1,provider:"OpenAI",model:"gpt-4o-realtime-preview-2024-10-01"'
          replacement='realtimeConfig:{enable:!0,provider:"OpenAI",model:"gpt-4o-realtime-preview-2024-10-01"'
          find /app/.next -type f -name '*.js' -print0 \
            | xargs -0 sed -i "s|$${pattern}|$${replacement}|g" || true
          echo "[nextchat] realtime default enabled"
        fi
        if [ -n "$$PROXY_URL" ]; then
          export HOSTNAME="0.0.0.0"
          protocol=$$(echo $$PROXY_URL | cut -d: -f1)
          host=$$(echo $$PROXY_URL | cut -d/ -f3 | cut -d: -f1)
          port=$$(echo $$PROXY_URL | cut -d: -f3)
          conf=/etc/proxychains.conf
          echo "strict_chain" > $$conf
          echo "proxy_dns" >> $$conf
          echo "remote_dns_subnet 224" >> $$conf
          echo "tcp_read_time_out 15000" >> $$conf
          echo "tcp_connect_time_out 8000" >> $$conf
          echo "localnet 127.0.0.0/255.0.0.0" >> $$conf
          echo "localnet ::1/128" >> $$conf
          echo "[ProxyList]" >> $$conf
          echo "$$protocol $$host $$port" >> $$conf
          cat /etc/proxychains.conf
          exec proxychains -f $$conf node server.js
        else
          exec node server.js
        fi
    ports:
      - "${NEXTCHAT_PORT:-3000}:3000"
    depends_on:
      api:
        condition: service_started
